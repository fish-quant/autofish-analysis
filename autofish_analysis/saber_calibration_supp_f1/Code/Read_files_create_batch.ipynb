{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook of the pipeline. The project is structured around three folders: Acquisition, Analysis and Code. \n",
    "Acquisition stores all the data, Analysis the results (and the intermediary results) and Code, the present notebooks. \n",
    "Both in Acquisition and Analysis we create one folder per experiment type (called batch). Inside each batch folder, we will keep a similar folder structure.\n",
    "\n",
    "Create a batch name, a name that will encompass a hole set of experiments\n",
    "for instance different repetitions of experiments A, B, C. \n",
    "\n",
    "Each batch will be stored in separate folder inside the analysis folder in which all the results will be stored.\n",
    "\n",
    "Jacques Bourg @ Florian Muller lab. Institut Pasteur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import skimage.io as io\n",
    "import shutil\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "base_dir = Path(\"../../src\").resolve()\n",
    "sys.path.append(str(base_dir))\n",
    "sys.path.append(str(base_dir / \"utils\"))\n",
    "\n",
    "from utils.parameters_tracking import Parameter_tracking as Track\n",
    "from utils.widgets import StringListWidget as Slw\n",
    "from utils.file_handling import FileProcessor as Fp\n",
    "\n",
    "fp  = Fp()\n",
    "tk  = Track()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = widgets.Text(value='',placeholder='Batch name to input', description='', disabled=False)\n",
    "display(text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_name = text_input.value; print(batch_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_batch = Path(f\"../Analysis/{batch_name}\")\n",
    "if not folder_path_batch.exists():\n",
    "    folder_path_batch.mkdir(parents=True)\n",
    "    \n",
    "folder_path_batch = Path(f\"../Acquisition/{batch_name}\")\n",
    "if not folder_path_batch.exists():\n",
    "    folder_path_batch.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This line defines three types of experiments/conditions that will take place in this batch: A,B, C. We will create a single folder for each condition.\n",
    "Set the names in capitals ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods = Slw(); mods.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modalities = mods.string_list; print(modalities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in modalities:\n",
    "    folder_path_modality = Path(f\"../Analysis/{batch_name}/{mod}\")\n",
    "    if not folder_path_modality.exists():\n",
    "        folder_path_modality.mkdir(parents=True)\n",
    " \n",
    "for mod in modalities:\n",
    "    folder_path_modality = Path(f\"../Acquisition/{batch_name}/{mod}\")\n",
    "    if not folder_path_modality.exists():\n",
    "        folder_path_modality.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets defines the types of channels that appear in this experiment, for instance: DAPI and FISH (if there are several fish call them FISH_1, FISH_2 or some other name).\n",
    "Set the names in capitals !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chans = Slw(); chans.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = chans.string_list; print(channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Associate a color with each channel, ni the same order (write in lowercase or in hex), this will be useful when plotting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = Slw(); cols.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = cols.string_list; print(colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter the two structures we are going to segment (usually NUCLEI and CELL in uppercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "structs = Slw(); structs.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strucs = structs.string_list; print(strucs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a folder for each channel inside each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in modalities:\n",
    "    for chan in channels:\n",
    "        folder_path_mods_chans = Path(f\"../Analysis/{batch_name}/{mod}/{chan}\")\n",
    "        if not folder_path_mods_chans.exists():\n",
    "            folder_path_mods_chans.mkdir(parents=True)\n",
    "            \n",
    "for mod in modalities:\n",
    "    for chan in channels:\n",
    "        folder_path_mods_chans = Path(f\"../Acquisition/{batch_name}/{mod}/{chan}\")\n",
    "        if not folder_path_mods_chans.exists():\n",
    "            folder_path_mods_chans.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_folder = fp.select_file(initialdir=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for lif files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_names, image_list = fp.read_lif_many_images(path_folder) # since it is a lif file, for nd2 files see and adapt method read_convert_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path_batch = Path(f\"../Analysis/{batch_name}/temp_file\")\n",
    "if not folder_path_batch.exists():\n",
    "    folder_path_batch.mkdir(parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_names = []\n",
    "for ind, image in enumerate(image_list):\n",
    "    filename = Path(f\"../Analysis/{batch_name}/temp_file\") / Path(images_names[ind]+'.tif')\n",
    "    io.imsave(filename, image, imagej=True)\n",
    "    path_names.append(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual intervention required: change the channel numbers (for instance channel_dapi ) and verify that the channel corresponds to what you are looking for. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = [Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X1X_2/1X1X_2_MMStack_1-Pos000_000.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X1X_4/1X1X_4_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X1X_5/1X1X_5_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X2X_1/1X2X_1_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X2X_2/1X2X_2_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/1X2X_4/1X2X_4_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X1X_1/3X1X_1_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X1X_3/3X1X_3_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X1X_4/3X1X_4_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X2X_1/3X2X_1_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X2X_2/3X2X_2_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/3X2X_3/3X2X_3_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X1X_1/30X1X_1_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X1X_2/30X1X_2_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X1X_3/30X1X_3_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X2X_1/30X2X_1_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X2X_2/30X2X_2_MMStack_Pos0.ome.tif'),\n",
    "              Path('/media/PBI_big_data/rna-imaging/data/smFISH-optimization/SABER/2025-04-19_SABER/For-Analysis/30X2X_3/30X2X_3_MMStack_Pos0.ome.tif'),\n",
    "              ]\n",
    "\n",
    "for u in image_path:\n",
    "    print(os.path.isfile(u))\n",
    "\n",
    "channel_dapi  = 1\n",
    "channel_fish  = 0\n",
    "\n",
    "\n",
    "channels_num  = [channel_dapi, channel_fish]#, channel_fish]\n",
    "print('corresponding channels :',  channels_num)\n",
    "\n",
    "\n",
    "name_cond = modalities[0]\n",
    "                                                                       #  the name of the condition/modalities must be among the modalities listed just before. \n",
    "for ind, chan in enumerate(channels_num):\n",
    "    folder_dirs = []\n",
    "    for ind_image, name in enumerate(image_path):                      # This cell separates the files in channels and stores them in the corresponding condition / channel folder\n",
    "        im_c      = io.imread(name)                                    # image_list[indexes_ims[ind]][chan,...]\n",
    "        \n",
    "        if im_c.ndim == 5:\n",
    "            im_out = im_c[0][chan]\n",
    "        elif im_c.ndim == 4:\n",
    "            im_out = im_c[chan]\n",
    "\n",
    "        f_name    = Path(name).stem\n",
    "        file_path = str(Path(f\"../Acquisition/{batch_name}/{name_cond}\")/ Path(channels[ind]) / Path(f_name + f'_{channels[ind]}.tif'))\n",
    "        io.imsave(file_path, im_out)\n",
    "        folder_dirs.append(file_path)\n",
    "        \n",
    "    exec(f\"BATCH_{name_cond}_{channels[ind]} = folder_dirs\", globals())  # create the uppercased variables  (condition, channel) containing the list of all the associated files\n",
    "                                                                         # for instance BATCH_LNP_DAPI       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For each condition: manually affect the experiments to each condition:\n",
    "   Among the list of image names, choose the ones that must be affected to each condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(images_names)\n",
    "list_same_cond = [images_names[0], images_names[1], images_names[3]]   # Choose the images for a given condition.\n",
    "indexes_ims    = [0, 1, 3]                                             # copy the indexes of the images \n",
    "name_cond      = 'LNP'                                                 # the name of the condition/modalities must be among the modalities listed just before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ind_image, name in enumerate(list_same_cond):                      # This cell separates the files in channels and stores them in the corresponding condition / channel folder\n",
    "    folder_dirs = []\n",
    "    for ind, chan in enumerate(channels_num):\n",
    "        im_c      = image_list[indexes_ims[ind]][chan,...]\n",
    "        file_path = str(Path(f\"../Acquisition/{batch_name}/{name_cond}\")/ Path(channels[ind]) / Path(name + f'_{channels[ind]}.tif'))\n",
    "        io.imsave(file_path, im_c)\n",
    "        folder_dirs.append(file_path)\n",
    "        \n",
    "    exec(f\"BATCH_{name_cond}_{channels[ind]} = folder_dirs\", globals())  # create the uppercased variables  (condition, channel) containing the list of all the associated files\n",
    "                                                                         # for instance BATCH_LNP_DAPI        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once all the channels of each condition were affected in a specific folder as a separate .tif file, erase the /temp_file folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(Path(f\"../Analysis/{batch_name}/temp_file\")):\n",
    "    shutil.rmtree(Path(f\"../Analysis/{batch_name}/temp_file\"))  # Remove the folder and all its contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally execute these last cells to collect the constants.\n",
    "#### The convention is to write the constants that we want to pass by to the other notebooks in uppercase at the end of the notebook.\n",
    "#### This will create a json file that will be used to communicate between notebooks used in a same batch of experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODALITIES   = modalities\n",
    "CHANNELS     = channels\n",
    "BATCH_NAME   = batch_name\n",
    "CHANNELS_NUM = channels_num\n",
    "COLORS       = colors\n",
    "STRUCTURES   = strucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constants2 = tk.collect_constants()\n",
    "tk.save_constants_and_commit_hash(constants2, BATCH_NAME, folder_path = Path(f\"../Analysis/{BATCH_NAME}\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_env_apifish",
   "language": "python",
   "name": "base_env_apifish"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
